{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0034a6df",
   "metadata": {},
   "source": [
    "# Active-learning tutorial: Using committee MACE models to study protonated water clusters\n",
    "\n",
    "1. Load all the modules\n",
    "2. read the training pool \n",
    "3. select random training set of 25 structure from the pool (can be done with np.rand) --> latter exclude these from the pool\n",
    "4. Train a committee (just to check we can train 2)\n",
    "5. predict on the training pool and sort max energy error\n",
    "6. Then we repeat in a for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad02c8",
   "metadata": {},
   "source": [
    "## To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a8f15",
   "metadata": {},
   "source": [
    "- for loop everywhere\n",
    "- avoid using scripts for MACE\n",
    "- fix E0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='../initial-datasets/zundel/zundel.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec7dae",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ase.io import read, write # read and write structures\n",
    "# from ase.visualize import view # visualize structures (optional)\n",
    "\n",
    "# import functions to run this tutorial\n",
    "from myfunctions import train_mace     # train MACE model\n",
    "from myfunctions import eval_mace      # evaluate MACE model\n",
    "from myfunctions import extxyz2energy  # extract energy from extxyz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c06c11-8556-4fb8-a500-72b08bd44e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "plt.style.use('notebook.mplstyle')\n",
    "os.makedirs('config', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('structures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_init_train = 20\n",
    "n_test = 50  \n",
    "n_committee = 4\n",
    "parallel = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c375f6e",
   "metadata": {},
   "source": [
    "## Select initial training structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the all the structures from file\n",
    "structures = read('../initial-datasets/zundel/train.extxyz', index=':')\n",
    "print(f'Total number of structures: {len(structures)}')\n",
    "# view(structures)  # Opens an interactive GUI window to visualize the structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial training and test sets\n",
    "selected_indices = np.random.choice(len(structures), size=(n_init_train + n_test), replace=False)\n",
    "remaining_candidate_idcs = np.delete(np.arange(len(structures)), selected_indices)\n",
    "\n",
    "indices_train = selected_indices[:n_init_train]\n",
    "indices_test = selected_indices[n_init_train:]\n",
    "assert len(indices_train) == n_init_train\n",
    "assert len(indices_test) == n_test\n",
    "\n",
    "print(f'\\nSelected indices for training: {indices_train}')\n",
    "print(f'\\nSelected indices for test: {indices_test}')\n",
    "\n",
    "initial_training_set = [structures[i] for i in indices_train]\n",
    "test_set = [structures[i] for i in indices_test]\n",
    "remaining_structures = [structures[i] for i in remaining_candidate_idcs]\n",
    "\n",
    "print(f\"\\nSaving the initial training set to 'structures/init.train.extxyz'\")\n",
    "write('structures/init.train.extxyz', initial_training_set, format='extxyz')\n",
    "\n",
    "print(f\"\\nSaving the test set to 'structures/test.extxyz'\")\n",
    "write('structures/test.extxyz', test_set, format='extxyz')\n",
    "\n",
    "print(f\"\\nSaving the remaining structures to 'structures/remaining.extxyz'\")\n",
    "write('structures/remaining.extxyz', remaining_structures, format='extxyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1077ec",
   "metadata": {},
   "source": [
    "## Initial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf1a48",
   "metadata": {},
   "source": [
    "Hyperparameters for the committee members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different values for each config\n",
    "os.makedirs('config', exist_ok=True)\n",
    "seeds = np.random.randint(0, 2**32 - 1, size=n_committee, dtype=np.uint32)\n",
    "for i in range(n_committee):\n",
    "    filename = f\"config/config.{i}.yml\"\n",
    "    name = f\"mace.com={i}\"\n",
    "    \n",
    "    config_text = f\"\"\"\n",
    "# You can modify the following parameters\n",
    "num_channels: 16\n",
    "max_L: 0            # take it larger but not smaller\n",
    "max_ell: 1          # take it larger but not smaller\n",
    "correlation: 1      # take it larger but not smaller\n",
    "num_interactions: 2 # take it larger but not smaller\n",
    "\n",
    "# ... but you can also modify these ones\n",
    "r_max: 4.0\n",
    "batch_size: 4\n",
    "max_num_epochs: 100\n",
    "\n",
    "# But please, do not modify these parameters!\n",
    "model: \"MACE\"\n",
    "name: \"{name}\"\n",
    "model_dir: \"models\"\n",
    "log_dir: \"log\"\n",
    "checkpoints_dir: \"checkpoints\"\n",
    "results_dir: \"results\"\n",
    "train_file: \"structures/init.train.extxyz\"\n",
    "energy_key: \"REF_energy\"\n",
    "forces_key: \"REF_forces\"\n",
    "E0s: \"average\" # to be fixed\n",
    "device: cpu\n",
    "swa: true\n",
    "seed: {seeds[i]}\n",
    "restart_latest: True\n",
    "\"\"\"\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(config_text)\n",
    "\n",
    "    print(f\"Wrote {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4113a-b80f-47c4-8d19-5b02e6afa0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a committee of MACE models\n",
    "os.makedirs('models', exist_ok=True)\n",
    "parallel = False\n",
    "if parallel:\n",
    "    def train_single_model(n):\n",
    "        config_path = f\"config/config.{n}.yml\"\n",
    "        with open(\"test.txt\", 'w') as fnull:\n",
    "            with redirect_stdout(fnull), redirect_stderr(fnull):\n",
    "                train_mace(config_path)\n",
    "            \n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        pool.map(train_single_model, range(n_committee))\n",
    "else:    \n",
    "    for n in range(n_committee):\n",
    "        with open(os.devnull, 'w') as fnull:\n",
    "            with redirect_stdout(fnull), redirect_stderr(fnull):\n",
    "                train_mace(f\"config/config.{n}.yml\")\n",
    "        \n",
    "# it should take around 25s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702a1a9-b2e0-4fbd-887c-56ad928caa39",
   "metadata": {},
   "source": [
    "Train a committee of MACE models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless files\n",
    "for filename in os.listdir('log'):\n",
    "    if filename.endswith('_debug.log'):\n",
    "        file_path = os.path.join('log', filename)\n",
    "        os.remove(file_path)\n",
    "        \n",
    "for n in range(n_committee):\n",
    "    \n",
    "    # models\n",
    "    filenames = [f\"models/mace.com={n}.model\",\n",
    "                 f\"models/mace.com={n}_compiled.model\",\n",
    "                 f\"models/mace.com={n}_stagetwo.model\"]\n",
    "    for filename in filenames:\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "    \n",
    "    if os.path.exists(f\"models/mace.com={n}_stagetwo_compiled.model\"):\n",
    "        os.rename(f\"models/mace.com={n}_stagetwo_compiled.model\",f\"models/mace.n={n}.model\")\n",
    "    \n",
    "for filename in os.listdir('results'):\n",
    "    if filename.endswith('.txt') or filename.endswith('stage_one.png'):\n",
    "        file_path = os.path.join('results', filename)\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65168375",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30d5e4-fb47-4235-9637-e52e1cf3822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tqdm(range(n_committee)):\n",
    "    eval_mace(f'models/mace.n={n:d}.model', '../initial-datasets/zundel/train.extxyz', f'eval_train_{n:02d}.extxyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18d050-c7a9-4eb7-aa28-1e980719676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in predicted energies\n",
    "energies = np.array([extxyz2energy(f'eval_train_{n:02d}.extxyz') for n in tqdm(range(n_committee))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782b3b8-7d8c-467a-bbdd-c8a627d93cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_energy = energies.mean(axis=0)\n",
    "disagreement = energies.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc857067",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, e in enumerate(energies):\n",
    "    plt.plot(e, label=rf'$E_{n:d}$', alpha=0.5)\n",
    "plt.plot(avg_energy, label=r'$\\overline{E}$', color='k')\n",
    "plt.legend()\n",
    "plt.xlabel('Data point index')\n",
    "plt.ylabel('Energy [eV]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(disagreement)\n",
    "plt.xlabel('Data point index')\n",
    "plt.ylabel(r'$\\sigma(E)$ [eV]');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7ceed-f6c9-4f6a-ae51-5c1dd9f47efa",
   "metadata": {},
   "source": [
    "# Select relevant training data via Query by Committee (QbC)\n",
    "\n",
    "Some text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qbc(fns_committee, fn_candidates, fn_train_init, n_iter, n_add_iter=10, recalculate_selected=False, calculator=None):\n",
    "    \"\"\"Main QbC loop.\"\"\"\n",
    "    # TODO: Add the possibility of attaching a ASE calculator for later when we need to address unlabeled data.\n",
    "    # TODO: think about striding the candidates to make it more efficient\n",
    "    # TODO: start from training set size 0?\n",
    "\n",
    "    print(f'Starting QbC.')\n",
    "    print(f'{n_iter:d} iterations will be done in total and {n_add_iter:d} will be added every iteration.')\n",
    "\n",
    "    #os.makedirs('QbC', exist_ok=True)\n",
    "\n",
    "    candidates = read(fn_candidates, index=':')\n",
    "    training_set = []\n",
    "    progress_disagreement = []\n",
    "    for _ in tqdm(range(n_iter)):\n",
    "\n",
    "        # predict disagreement on all candidates\n",
    "        print(f'Predicting committee disagreement across the candidate pool.')\n",
    "        energies = []\n",
    "        for n, model in enumerate(fns_committee):\n",
    "            fn_dump = f'eval_train_{n:02d}.extxyz'\n",
    "            eval_mace(model, fn_candidates, fn_dump) # Explicit arguments!\n",
    "            e = extxyz2energy(fn_dump)\n",
    "            energies.append(e)\n",
    "        energies = np.array(energies)\n",
    "        disagreement = energies.std(axis=0)\n",
    "        avg_disagreement_pool = disagreement.mean()\n",
    "\n",
    "        # pick the `n_add_iter` highest-disagreement structures\n",
    "        print(f'Picking {n_add_iter:d} new highest-disagreement data points.')\n",
    "        idcs_selected = np.argsort(disagreement)[-n_add_iter:]\n",
    "        print(idcs_selected)\n",
    "        avg_disagreement_selected = (disagreement[idcs_selected]).mean()\n",
    "        progress_disagreement.append(np.array([avg_disagreement_selected, avg_disagreement_pool]))\n",
    "        # TODO: an ASE calculator will come here\n",
    "        if recalculate_selected:\n",
    "            assert calculator is not None, 'If a first-principles recalculation of training data is requested, a corresponding ASE calculator must be assigned.'\n",
    "            print(f'Recalculating ab initio energies and forces for new data points.')\n",
    "            for structure in candidates[idcs_selected]:\n",
    "                structure.calc = calculator\n",
    "                structure.get_potential_energy()\n",
    "                structure.get_forces()\n",
    "        #training_set.append([candidates[i] for i in idcs_selected])\n",
    "        #candidates = np.delete(candidates, idcs_selected)\n",
    "        # TODO: super ugly, make it better\n",
    "        for i in idcs_selected:\n",
    "            training_set.append(candidates[i])\n",
    "        for i in idcs_selected:\n",
    "            del candidates[i]\n",
    "\n",
    "        # dump files with structures\n",
    "        write('train-iter.extxyz', training_set, format='extxyz')\n",
    "        write('candidates.extxyz', candidates, format='extxyz')\n",
    "\n",
    "        # retrain the committee with the enriched training set\n",
    "        print(f'Retraining committee.')\n",
    "        # TODO: add multiprocessing\n",
    "        # TODO: add model refinement\n",
    "        for n in range(len(fns_committee)):\n",
    "            train_mace(f\"config/config.{n}.yml\")\n",
    "\n",
    "        # update the candidate file name\n",
    "        fn_candidates = 'candidates.extxyz'\n",
    "\n",
    "        print(f'Status at the end of this QbC iteration: Disagreement (pool) [eV]    Disagreement (selected) [eV]')\n",
    "        print(f'                                         {avg_disagreement_pool:06f} {avg_disagreement_selected:06f}')\n",
    "\n",
    "    # dump final training set\n",
    "    write('train-final.extxyz', training_set, format='extxyz')\n",
    "    np.savetxt('disagreement.txt', progress_disagreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485214c3-454e-437c-af4c-4752441d7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different values for each config\n",
    "# TODO: make this simpler - the only thing we need to change is the name of the training extxyz file.\n",
    "# TODO: implement retraining using the refinement workflow using `foundation_model`\n",
    "os.makedirs('config', exist_ok=True)\n",
    "seeds = np.random.randint(0, 2**32 - 1, size=n_committee, dtype=np.uint32)\n",
    "for i in range(n_committee):\n",
    "    filename = f\"config/config.{i}.yml\"\n",
    "    name = f\"mace.com={i}\"\n",
    "    \n",
    "    config_text = f\"\"\"\n",
    "# You can modify the following parameters\n",
    "num_channels: 16\n",
    "max_L: 0            # take it larger but not smaller\n",
    "max_ell: 1          # take it larger but not smaller\n",
    "correlation: 1      # take it larger but not smaller\n",
    "num_interactions: 2 # take it larger but not smaller\n",
    "\n",
    "# ... but you can also modify these ones\n",
    "r_max: 4.0\n",
    "batch_size: 4\n",
    "max_num_epochs: 100\n",
    "\n",
    "# But please, do not modify these parameters!\n",
    "model: \"MACE\"\n",
    "name: \"{name}\"\n",
    "model_dir: \"models\"\n",
    "log_dir: \"log\"\n",
    "checkpoints_dir: \"checkpoints\"\n",
    "results_dir: \"results\"\n",
    "train_file: \"train-iter.extxyz\"\n",
    "energy_key: \"REF_energy\"\n",
    "forces_key: \"REF_forces\"\n",
    "E0s: \"average\" # to be fixed\n",
    "device: cpu\n",
    "swa: true\n",
    "seed: {seeds[i]}\n",
    "restart_latest: True\n",
    "\"\"\"\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(config_text)\n",
    "\n",
    "    print(f\"Wrote {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea7598-e484-4604-81ff-a2977c0a431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_committee = [f'models/mace.n={n:d}.model' for n in range(n_committee)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_qbc(\n",
    "    fns_committee=fns_committee,\n",
    "    fn_candidates='structures/remaining.extxyz',\n",
    "    fn_train_init='structures/init.train.extxyz',\n",
    "    n_iter=5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d99050",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.loadtxt('disagreement.txt').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151639c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigma[0], '-o', label='Selected')\n",
    "plt.plot(sigma[1], '-o', label='Candidates')\n",
    "plt.legend()\n",
    "plt.xlabel('QbC iteration')\n",
    "plt.ylabel(r'$\\sigma(E) [eV]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac38781",
   "metadata": {},
   "source": [
    "## Run FHI-aims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616997ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfunctions import run_aims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f83f2a-217c-4ad1-9b35-eb91534c20ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run  = structures[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb693949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "run_aims(\n",
    "    structures=to_run,\n",
    "    folder='aims',\n",
    "    command=f\"mpirun -n 4 /home/stoccoel/codes/FHIaims-polarization/build/polarization-debug/aims.250131.scalapack.mpi.x\",\n",
    "    control=\"../aims/control.in\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d529494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
